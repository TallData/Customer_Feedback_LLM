{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c4b91ec-09fd-4a08-857d-6372355a118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#data process\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#data import\n",
    "import zipfile  \n",
    "import shutil\n",
    "import pandas as pd\n",
    "#data cleansing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import ssl\n",
    "import string\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a726688b-0e2f-4325-850e-b43a2058aac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer-support-on-twitter.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "Dataset downloaded and moved to the data folder successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "data_dir = 'data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Run the Kaggle API command to download the dataset\n",
    "!kaggle datasets download -d thoughtvector/customer-support-on-twitter -p {data_dir}\n",
    "\n",
    "# Unzip the downloaded dataset to the data directory\n",
    "zip_file_path = os.path.join(data_dir, 'customer-support-on-twitter.zip')\n",
    "extracted_folder_path = os.path.join(data_dir, 'twcs')\n",
    "\n",
    "# Extract the contents directly into the data folder\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_dir)\n",
    "\n",
    "# Move the contents of the 'twcs' folder to the 'data' folder\n",
    "for item in os.listdir(extracted_folder_path):\n",
    "    s = os.path.join(extracted_folder_path, item)\n",
    "    d = os.path.join(data_dir, item)\n",
    "    shutil.move(s, d)\n",
    "\n",
    "# Remove the now-empty 'twcs' folder\n",
    "os.rmdir(extracted_folder_path)\n",
    "\n",
    "# Display success message\n",
    "print(\"Dataset downloaded and moved to the data folder successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47b2b70-b266-4582-9a30-9f103d08af88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "         tweet_id     author_id  inbound                      created_at  \\\n",
      "160535     192624        161253     True  Wed Oct 04 13:59:33 +0000 2017   \n",
      "659248     738238        296574     True  Fri Oct 06 18:29:06 +0000 2017   \n",
      "2250310   2414302  AppleSupport    False  Tue Nov 14 17:38:01 +0000 2017   \n",
      "1640680   1793929        539096     True  Thu Oct 12 06:04:41 +0000 2017   \n",
      "1933623   2088018        617376     True  Mon Nov 06 20:30:49 +0000 2017   \n",
      "\n",
      "                                                      text response_tweet_id  \\\n",
      "160535   @161252 What's that egg website people talk about            192623   \n",
      "659248   Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...            738237   \n",
      "2250310  @693975 We can assist you. We recommend updati...           2414303   \n",
      "1640680  @331912 @115955 Thats better than having an un...           1793928   \n",
      "1933623  @VirginAmerica is probably one of the best air...           2088017   \n",
      "\n",
      "         in_response_to_tweet_id  \n",
      "160535                  192625.0  \n",
      "659248                       NaN  \n",
      "2250310                2414304.0  \n",
      "1640680                1793930.0  \n",
      "1933623                      NaN  \n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 160535 to 392446\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   tweet_id                 1000 non-null   int64  \n",
      " 1   author_id                1000 non-null   object \n",
      " 2   inbound                  1000 non-null   bool   \n",
      " 3   created_at               1000 non-null   object \n",
      " 4   text                     1000 non-null   object \n",
      " 5   response_tweet_id        643 non-null    object \n",
      " 6   in_response_to_tweet_id  720 non-null    float64\n",
      "dtypes: bool(1), float64(1), int64(1), object(4)\n",
      "memory usage: 55.7+ KB\n",
      "None\n",
      "\n",
      "Summary statistics:\n",
      "           tweet_id  in_response_to_tweet_id\n",
      "count  1.000000e+03             7.200000e+02\n",
      "mean   1.456100e+06             1.447198e+06\n",
      "std    8.668588e+05             8.685432e+05\n",
      "min    1.291000e+03             1.293000e+03\n",
      "25%    6.896212e+05             6.842462e+05\n",
      "50%    1.431694e+06             1.406170e+06\n",
      "75%    2.215524e+06             2.220165e+06\n",
      "max    2.978464e+06             2.978465e+06\n",
      "\n",
      "Number of rows: 1000, Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "# Specify the size of the random sample\n",
    "sample_size = 1000  # Adjust the sample size as needed\n",
    "random_seed = 42  # Set a random seed for reproducibility\n",
    "\n",
    "# Load a random sample of the dataset into a Pandas DataFrame\n",
    "\n",
    "dataset_path = 'data/twcs.csv'\n",
    "df_full = pd.read_csv(dataset_path)\n",
    "\n",
    "# Take a random sample of the dataset\n",
    "np.random.seed(random_seed)\n",
    "random_indices = np.random.choice(df_full.index, size=sample_size, replace=False)\n",
    "df = df_full.loc[random_indices]\n",
    "\n",
    "# Display the first few rows of the DataFrame to understand the structure\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Save the first few rows to a sample CSV file\n",
    "sample_path = 'data/sample_dataset.csv'\n",
    "df.head().to_csv(sample_path, index=False)\n",
    "\n",
    "# Display general information about the dataset\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Display basic statistics of numerical columns\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Display the number of rows and columns in the dataset\n",
    "rows, cols = df.shape\n",
    "print(f\"\\nNumber of rows: {rows}, Number of columns: {cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3158fefd-53c0-42d6-8c5f-52101dbdfde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 160535 to 392446\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   tweet_id                 1000 non-null   int64  \n",
      " 1   author_id                1000 non-null   object \n",
      " 2   inbound                  1000 non-null   bool   \n",
      " 3   created_at               1000 non-null   object \n",
      " 4   text                     1000 non-null   object \n",
      " 5   response_tweet_id        643 non-null    object \n",
      " 6   in_response_to_tweet_id  720 non-null    float64\n",
      "dtypes: bool(1), float64(1), int64(1), object(4)\n",
      "memory usage: 55.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display information about the DataFrame\n",
    "print(\"DataFrame Information:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc11c1fd-f85e-4050-89c1-c7f891ded502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Text:\n",
      " @161252 What's that egg website people talk about\n",
      "Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BXr...\n",
      "@693975 We can assist you. We recommend updatin...\n",
      "@331912 @115955 Thats better than having an uns...\n",
      "@VirginAmerica is probably one of the best airl...\n"
     ]
    }
   ],
   "source": [
    "#Display the first few rows of the DataFrame\n",
    "print(\"\\nOriginal Text:\")\n",
    "print(df['text'].head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1506f0de-b4b2-48d0-9d1d-82ac1693a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display a separator\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda6fb07-dc9a-44b0-b2b5-395b300cd8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to NLTK data\n",
    "nltk.data.path.append(\"/Users/stak/Dev/Customer_Feedback_LLM/data/nltk_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4e423ab-66ce-4c2e-8be7-36b80412fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Remove links and unnecessary characters\n",
    "    text = ' '.join(word for word in text.split() if not word.startswith('http') and word not in string.punctuation)\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text into individual words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Debugging statements\n",
    "    #print(\"\\nOriginal Text:\")\n",
    "    #print(text)\n",
    "    #print(\"\\nTokens After Lowercasing and Tokenization:\")\n",
    "    #print(tokens)\n",
    "    #print(\"\\nTokens After Removing Stop Words:\")\n",
    "    #print(tokens)\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply the preprocessing function to the 'text' column\n",
    "df['preprocessed_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Display the first few rows of the DataFrame with the preprocessed text\n",
    "#print(\"Preprocessed Text:\")\n",
    "#print(df['preprocessed_text'].sample(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b147b6ed-bd09-4a37-9f76-d2b1def5e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment polarity\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "# Apply the sentiment analysis function to the 'preprocessed_text' column\n",
    "df['sentiment_polarity'] = df['preprocessed_text'].apply(get_sentiment)\n",
    "\n",
    "# Display the first few rows with sentiment polarity\n",
    "#print(\"\\nSentiment Polarity:\")\n",
    "#print(df[['preprocessed_text', 'sentiment_polarity']].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fce69c70-6e86-4607-a6a3-d649257d6570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 160535 to 392446\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   tweet_id                 1000 non-null   int64  \n",
      " 1   author_id                1000 non-null   object \n",
      " 2   inbound                  1000 non-null   bool   \n",
      " 3   created_at               1000 non-null   object \n",
      " 4   text                     1000 non-null   object \n",
      " 5   response_tweet_id        643 non-null    object \n",
      " 6   in_response_to_tweet_id  720 non-null    float64\n",
      " 7   preprocessed_text        1000 non-null   object \n",
      " 8   sentiment_polarity       1000 non-null   float64\n",
      "dtypes: bool(1), float64(2), int64(1), object(5)\n",
      "memory usage: 71.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display information about the DataFrame\n",
    "print(\"DataFrame Information:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae06a34-5c95-4a52-80be-bf93cd92e155",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
